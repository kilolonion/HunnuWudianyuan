import streamlit as st
from docx import Document
from docx.shared import Pt
from docx.oxml.ns import qn
from docx.enum.text import WD_PARAGRAPH_ALIGNMENT
from pathlib import Path
import re
import os
import tempfile
import base64
import io
import json
import datetime
import hashlib
import importlib.metadata
import shutil

# æ£€æŸ¥OpenAIç‰ˆæœ¬
try:
    openai_version = importlib.metadata.version("openai")
    is_old_api = openai_version.startswith("0.")
except:
    # å¦‚æœæ— æ³•ç¡®å®šç‰ˆæœ¬ï¼Œå‡å®šä¸ºæ–°ç‰ˆAPI
    is_old_api = False

import openai
from concurrent.futures import ThreadPoolExecutor

# é»˜è®¤é…ç½®
DEFAULT_CONFIG = {
    "title_keywords": ["ä¸¾åŠ", "å¼€å±•", "ååŠ©", "ç»„ç»‡", "å¬å¼€", "ä¸¾è¡Œ", "å®£è®²ä¼š", "å¿—æ„¿æ´»åŠ¨", "åŸ¹è®­ä¼š", "ç«èµ›"],
    "image_keywords": [
        "ä¸»æŒäºº", "å‘è¨€", "æˆè¯¾", "è®²è§£", "æ¥å¬ç”µè¯", "è¯„åˆ†", "ä½œç­”", "å±•ç¤º", "åˆ†äº«ç»éªŒ",
        "è®¤çœŸå¬è®²", "å·¥ä½œäººå‘˜åˆå½±", "å¿—æ„¿è€…", "é€‰æ‰‹æ¼”è®²", "é€‰æ‰‹å±•ç¤º", "ä¸»è®²äºº", "åˆå½±"
    ],
    "redundant_keywords": ["å‘å¸ƒäºº", "æµè§ˆæ•°", "æ—¥æœŸ"],
    "ai_settings": {
        "api_key": "",
        "model": "gpt-3.5-turbo",
        "api_base": ""
    },
    "formatting": {
        "font_name": "å®‹ä½“",
        "font_size": 12,
        "indent": True
    }
}

# è·å–é…ç½®ç›®å½•
def get_config_dir():
    if 'config_dir' in st.session_state and st.session_state.config_dir:
        config_dir = st.session_state.config_dir
    else:
        # é»˜è®¤é…ç½®ç›®å½•
        config_dir = os.path.join(os.environ.get('APPDATA', 'C:\\'), 'WordFormatter')
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    if not os.path.exists(config_dir):
        try:
            os.makedirs(config_dir)
        except Exception as e:
            st.error(f"æ— æ³•åˆ›å»ºé…ç½®ç›®å½•: {str(e)}")
            return None
    
    return config_dir

# è·å–é…ç½®æ–‡ä»¶è·¯å¾„
def get_config_path():
    config_dir = get_config_dir()
    if not config_dir:
        return None
    return os.path.join(config_dir, 'config.json')

# ä¿å­˜é…ç½®
def save_config(config):
    config_path = get_config_path()
    if not config_path:
        return False
    
    try:
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        st.error(f"ä¿å­˜é…ç½®å¤±è´¥: {str(e)}")
        return False

# åŠ è½½é…ç½®
def load_config():
    config_path = get_config_path()
    if not config_path or not os.path.exists(config_path):
        # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºé»˜è®¤é…ç½®
        default_config = DEFAULT_CONFIG.copy()
        save_config(default_config)
        return default_config
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        # æ£€æŸ¥å¹¶å¡«å……ç¼ºå¤±çš„é…ç½®é¡¹
        for key, value in DEFAULT_CONFIG.items():
            if key not in config:
                config[key] = value
            elif isinstance(value, dict):
                for sub_key, sub_value in value.items():
                    if sub_key not in config[key]:
                        config[key][sub_key] = sub_value
        
        return config
    except Exception as e:
        st.error(f"åŠ è½½é…ç½®å¤±è´¥: {str(e)}")
        return DEFAULT_CONFIG.copy()

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
def init_session_state():
    # åŠ è½½é…ç½®
    config = load_config()
    
    # è®¾ç½®ä¼šè¯çŠ¶æ€
    if 'title_keywords' not in st.session_state:
        st.session_state.title_keywords = config['title_keywords']
    if 'image_keywords' not in st.session_state:
        st.session_state.image_keywords = config['image_keywords']
    if 'redundant_keywords' not in st.session_state:
        st.session_state.redundant_keywords = config['redundant_keywords']
    if 'enable_ai' not in st.session_state:
        st.session_state.enable_ai = False
    if 'api_key' not in st.session_state:
        st.session_state.api_key = config['ai_settings']['api_key']
    if 'model' not in st.session_state:
        st.session_state.model = config['ai_settings']['model']
    if 'api_base' not in st.session_state:
        st.session_state.api_base = config['ai_settings']['api_base']
    if 'font_name' not in st.session_state:
        st.session_state.font_name = config['formatting']['font_name']
    if 'font_size' not in st.session_state:
        st.session_state.font_size = config['formatting']['font_size']
    if 'indent' not in st.session_state:
        st.session_state.indent = config['formatting']['indent']

# æ›´æ–°é…ç½®
def update_config():
    config = {
        "title_keywords": st.session_state.title_keywords,
        "image_keywords": st.session_state.image_keywords,
        "redundant_keywords": st.session_state.redundant_keywords,
        "ai_settings": {
            "api_key": st.session_state.api_key,
            "model": st.session_state.model,
            "api_base": st.session_state.api_base
        },
        "formatting": {
            "font_name": st.session_state.font_name,
            "font_size": st.session_state.font_size,
            "indent": st.session_state.indent
        }
    }
    return save_config(config)

# æ ‡é¢˜å…³é”®è¯
TITLE_KEYWORDS = ["ä¸¾åŠ", "å¼€å±•", "ååŠ©", "ç»„ç»‡", "å¬å¼€", "ä¸¾è¡Œ", "å®£è®²ä¼š", "å¿—æ„¿æ´»åŠ¨", "åŸ¹è®­ä¼š", "ç«èµ›"]

# å›¾ç‰‡è¯´æ˜å…³é”®è¯ï¼ˆç”¨äºå‰”é™¤ï¼‰
IMAGE_CAPTION_KEYWORDS = [
    "ä¸»æŒäºº", "å‘è¨€", "æˆè¯¾", "è®²è§£", "æ¥å¬ç”µè¯", "è¯„åˆ†", "ä½œç­”", "å±•ç¤º", "åˆ†äº«ç»éªŒ",
    "è®¤çœŸå¬è®²", "å·¥ä½œäººå‘˜åˆå½±", "å¿—æ„¿è€…", "é€‰æ‰‹æ¼”è®²", "é€‰æ‰‹å±•ç¤º", "ä¸»è®²äºº", "åˆå½±"
]

# ç³»ç»Ÿå†—ä½™å…³é”®è¯
REDUNDANT_KEYWORDS = ["å‘å¸ƒäºº", "æµè§ˆæ•°", "æ—¥æœŸ"]

def is_image_caption(text, image_keywords=None):
    if image_keywords is None:
        image_keywords = st.session_state.image_keywords if hasattr(st.session_state, 'image_keywords') else DEFAULT_CONFIG["image_keywords"]
    return any(k in text for k in image_keywords) and len(text) <= 20

def is_redundant(text):
    redundant_kw = st.session_state.redundant_keywords if hasattr(st.session_state, 'redundant_keywords') else DEFAULT_CONFIG["redundant_keywords"]
    return any(k in text for k in redundant_kw)

def is_title(text, title_keywords=None):
    if title_keywords is None:
        title_keywords = st.session_state.title_keywords if hasattr(st.session_state, 'title_keywords') else DEFAULT_CONFIG["title_keywords"]
    return any(k in text for k in title_keywords) and len(text) <= 40

def normalize_review_info(text):
    pattern = re.compile(r"(ä¸€å®¡|äºŒå®¡|ä¸‰å®¡)[ï¼š: ]?\s*([\u4e00-\u9fa5]{2,})")
    return [f"{label}ï¼š{name}" for label, name in pattern.findall(text)]

def set_style(p, font_name="å®‹ä½“", font_size=12, bold=False, indent=True, align_left=False):
    run = p.runs[0] if p.runs else p.add_run()
    run.font.name = font_name
    run.font.size = Pt(font_size)
    run.bold = bold
    if run._element.rPr is not None:
        run._element.rPr.rFonts.set(qn('w:eastAsia'), font_name)
    p.paragraph_format.first_line_indent = Pt(0 if not indent else 21)
    p.paragraph_format.line_spacing = 1.5
    if align_left:
        p.alignment = WD_PARAGRAPH_ALIGNMENT.LEFT

def process_docx(input_path, output_path, title_keywords=None, image_keywords=None,
                font_name="å®‹ä½“", font_size=12, indent=True, progress_callback=None):
    doc = Document(input_path)
    new_doc = Document()
    seen_titles = set()
    
    # ä½¿ç”¨ä¼ å…¥çš„å…³é”®è¯æˆ–é»˜è®¤å€¼
    title_kw = title_keywords if title_keywords else TITLE_KEYWORDS
    image_kw = image_keywords if image_keywords else IMAGE_CAPTION_KEYWORDS
    
    total_paragraphs = len(doc.paragraphs)

    for i, para in enumerate(doc.paragraphs):
        # æ›´æ–°è¿›åº¦
        if progress_callback and total_paragraphs > 0:
            progress_value = int((i / total_paragraphs) * 100)
            progress_callback(progress_value, f"å¤„ç†æ®µè½ {i+1}/{total_paragraphs}")
        
        text = para.text.strip()
        if not text:
            continue
            
        # æ£€æŸ¥æ˜¯å¦ä¸ºå›¾ç‰‡è¯´æ˜
        if is_image_caption(text, image_kw):
            continue
            
        if is_redundant(text):
            continue
            
        if text.startswith("[ç‰©ç”µé™¢]"):
            if text not in seen_titles:
                seen_titles.add(text)
                p = new_doc.add_paragraph(text)
                set_style(p, font_name="é»‘ä½“", font_size=16, bold=True, indent=False, align_left=True)
            continue
            
        # æ£€æŸ¥æ˜¯å¦ä¸ºæ ‡é¢˜
        if is_title(text, title_kw):
            tagged = f"[ç‰©ç”µé™¢] {text}"
            if tagged not in seen_titles:
                seen_titles.add(tagged)
                p = new_doc.add_paragraph(tagged)
                set_style(p, font_name="é»‘ä½“", font_size=16, bold=True, indent=False, align_left=True)
            continue
            
        if text.startswith("ï¼ˆé€šè®¯å‘˜"):
            p = new_doc.add_paragraph(text)
            set_style(p, indent=False)
            continue
            
        if any(k in text for k in ["ä¸€å®¡", "äºŒå®¡", "ä¸‰å®¡"]):
            for line in normalize_review_info(text):
                p = new_doc.add_paragraph(line)
                set_style(p, indent=False)
            continue
            
        # æ™®é€šæ­£æ–‡
        p = new_doc.add_paragraph(text)
        set_style(p, font_name=font_name, font_size=font_size, indent=indent)
    
    # ä¿å­˜æ–‡ä»¶
    if progress_callback:
        progress_callback(95, "æ­£åœ¨ä¿å­˜æ–‡ä»¶...")
    
    new_doc.save(output_path)

    if progress_callback:
        progress_callback(100, "å¤„ç†å®Œæˆ")

def extract_docx_text(docx_file):
    """
    ä»docxæ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹ç”¨äºé¢„è§ˆ
    """
    if isinstance(docx_file, str):  # å¦‚æœæ˜¯æ–‡ä»¶è·¯å¾„
        doc = Document(docx_file)
    else:  # å¦‚æœæ˜¯ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡
        doc = Document(io.BytesIO(docx_file.getvalue()))
    
    paragraphs = []
    for para in doc.paragraphs:
        text = para.text.strip()
        if text:
            paragraphs.append(text)
    
    return paragraphs

def render_preview(paragraphs, max_height=400):
    """
    æ¸²æŸ“æ–‡æ¡£é¢„è§ˆ
    """
    if not paragraphs:
        st.info("æ— å†…å®¹å¯é¢„è§ˆ")
        return
    
    # åˆ›å»ºä¸€ä¸ªå›ºå®šé«˜åº¦çš„å®¹å™¨ï¼Œå¸¦æ»šåŠ¨æ¡
    preview_container = st.container()
    
    # åœ¨å®¹å™¨ä¸­ä½¿ç”¨è‡ªå®šä¹‰CSSåˆ›å»ºä¸€ä¸ªå¯æ»šåŠ¨çš„åŒºåŸŸ
    scrollable_text = f"""
    <div style="height: {max_height}px; overflow-y: auto; border: 1px solid #e6e6e6; padding: 15px; border-radius: 5px; background-color: #f9f9f9;">
    """
    
    # æ·»åŠ æ®µè½
    for para in paragraphs[:100]:  # é™åˆ¶æœ€å¤šæ˜¾ç¤º100æ®µï¼Œé¿å…è¿‡å¤§
        if para.startswith("[ç‰©ç”µé™¢]") or (len(para) <= 40 and any(kw in para for kw in TITLE_KEYWORDS)):
            # æ ‡é¢˜æ ·å¼
            scrollable_text += f'<p style="font-weight: bold; font-size: 16px; margin-bottom: 8px;">{para}</p>'
        else:
            # æ™®é€šæ®µè½æ ·å¼
            scrollable_text += f'<p style="margin-bottom: 8px; text-indent: 2em;">{para}</p>'
    
    if len(paragraphs) > 100:
        scrollable_text += '<p style="color: #888;">...</p>'
    
    scrollable_text += "</div>"
    
    # æ˜¾ç¤ºé¢„è§ˆ
    preview_container.markdown(scrollable_text, unsafe_allow_html=True)

def get_binary_file_downloader_html(bin_file, file_label='æ–‡ä»¶'):
    with open(bin_file, 'rb') as f:
        data = f.read()
    b64 = base64.b64encode(data).decode()
    href = f'<a href="data:application/octet-stream;base64,{b64}" download="{os.path.basename(bin_file)}">{file_label}</a>'
    return href

def process_single_file(uploaded_file, title_keywords, image_keywords, font_name, font_size, indent):
    if uploaded_file is None:
        return None, None
        
    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
    temp_input = tempfile.NamedTemporaryFile(suffix='.docx', delete=False)
    temp_input.write(uploaded_file.getvalue())
    temp_input.close()
    
    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶è·¯å¾„
    temp_output = tempfile.NamedTemporaryFile(suffix='_æ ‡å‡†åŒ–å¤„ç†.docx', delete=False)
    temp_output.close()
    
    # å¤„ç†å‡½æ•°
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    def update_progress(value, message=""):
        progress_bar.progress(value / 100)
        status_text.text(message)
    
    try:
        process_docx(
            temp_input.name,
            temp_output.name,
            title_keywords=title_keywords,
            image_keywords=image_keywords,
            font_name=font_name,
            font_size=font_size,
            indent=indent,
            progress_callback=update_progress
        )
        
        # ç¡®ä¿è¾“å‡ºæ–‡ä»¶å­˜åœ¨
        if not os.path.exists(temp_output.name):
            st.error("å¤„ç†åçš„æ–‡ä»¶æœªæˆåŠŸç”Ÿæˆ")
            return None, None
            
        # è¿”å›å¤„ç†åçš„æ–‡ä»¶å’Œè¾“å‡ºæ–‡ä»¶è·¯å¾„
        output_paragraphs = extract_docx_text(temp_output.name)
        
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        if not output_paragraphs:
            st.warning("å¤„ç†åçš„æ–‡æ¡£å†…å®¹ä¸ºç©ºï¼Œè¯·æ£€æŸ¥å¤„ç†é€»è¾‘")
            
        return temp_output.name, output_paragraphs
    except Exception as e:
        st.error(f"å¤„ç†å‡ºé”™: {str(e)}")
        import traceback
        st.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return None, None
    finally:
        # æ¸…ç†ä¸´æ—¶è¾“å…¥æ–‡ä»¶
        if os.path.exists(temp_input.name):
            os.unlink(temp_input.name)

def process_batch_files(uploaded_files, title_keywords, image_keywords, font_name, font_size, indent):
    if not uploaded_files:
        return None
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_dir = tempfile.mkdtemp()
    output_files = []
    
    # æ‰¹é‡å¤„ç†è¿›åº¦æ¡
    batch_progress = st.progress(0)
    file_progress = st.progress(0)
    status_text = st.empty()
    
    for i, uploaded_file in enumerate(uploaded_files):
        # æ›´æ–°æ‰¹é‡å¤„ç†è¿›åº¦
        batch_value = int((i / len(uploaded_files)) * 100)
        batch_progress.progress(batch_value / 100)
        status_text.text(f"å¤„ç†æ–‡ä»¶ {i+1}/{len(uploaded_files)}: {uploaded_file.name}")
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        temp_input = tempfile.NamedTemporaryFile(suffix='.docx', delete=False)
        temp_input.write(uploaded_file.getvalue())
        temp_input.close()
        
        # åˆ›å»ºè¾“å‡ºæ–‡ä»¶è·¯å¾„
        output_filename = Path(uploaded_file.name).stem + "_æ ‡å‡†åŒ–å¤„ç†.docx"
        output_path = os.path.join(temp_dir, output_filename)
        
        # æ–‡ä»¶å¤„ç†è¿›åº¦å›è°ƒ
        def update_file_progress(value, message=""):
            file_progress.progress(value / 100)
        
        try:
            process_docx(
                temp_input.name,
                output_path,
                title_keywords=title_keywords,
                image_keywords=image_keywords,
                font_name=font_name,
                font_size=font_size,
                indent=indent,
                progress_callback=update_file_progress
            )
            output_files.append((output_filename, output_path))
        except Exception as e:
            st.error(f"å¤„ç†æ–‡ä»¶ {uploaded_file.name} å¤±è´¥: {str(e)}")
        finally:
            # æ¸…ç†ä¸´æ—¶è¾“å…¥æ–‡ä»¶
            os.unlink(temp_input.name)
    
    # å®Œæˆ
    batch_progress.progress(1.0)
    status_text.text("æ‰¹å¤„ç†å®Œæˆ")
    
    return output_files

def create_zip_of_files(files):
    import zipfile
    
    # åˆ›å»ºä¸´æ—¶zipæ–‡ä»¶
    temp_zip = tempfile.NamedTemporaryFile(suffix='.zip', delete=False)
    temp_zip.close()
    
    # æ·»åŠ æ–‡ä»¶åˆ°zip
    with zipfile.ZipFile(temp_zip.name, 'w') as zipf:
        for filename, filepath in files:
            zipf.write(filepath, arcname=filename)
    
    return temp_zip.name

def extract_content_for_ai(docx_file):
    """
    æå–æ–‡æ¡£å†…å®¹ï¼Œç”¨äºAIåˆ†æ
    """
    if isinstance(docx_file, str):  # å¦‚æœæ˜¯æ–‡ä»¶è·¯å¾„
        doc = Document(docx_file)
    else:  # å¦‚æœæ˜¯ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡
        doc = Document(io.BytesIO(docx_file.getvalue()))
    
    # æå–å‰3000ä¸ªå­—ç¬¦ç”¨äºåˆ†æ
    content = ""
    for para in doc.paragraphs:
        content += para.text + "\n"
        if len(content) > 3000:
            content = content[:3000]
            break
    
    return content

def analyze_with_openai(content, api_key, model, api_base=None):
    """
    ä½¿ç”¨OpenAI APIåˆ†ææ–‡æ¡£å†…å®¹ï¼Œæå–å…³é”®è¯
    """
    try:
        # è®¾ç½®APIå¯†é’¥
        openai.api_key = api_key
        
        # å‡†å¤‡å®¢æˆ·ç«¯å‚æ•°
        client_params = {"api_key": api_key}
        
        # å¦‚æœæä¾›äº†è‡ªå®šä¹‰APIåŸºç¡€URLï¼Œåˆ™è®¾ç½®å®ƒ
        if api_base and api_base.strip():
            if is_old_api:
                openai.api_base = api_base
            else:
                client_params["base_url"] = api_base
        
        # å¢å¼ºæç¤ºä¿¡æ¯
        prompt = f"""
        ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ–‡æ¡£åˆ†æå¸ˆï¼Œæ“…é•¿åˆ†æå­¦æœ¯æŠ¥å‘Šå’Œæ´»åŠ¨æ–‡æ¡£ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»ä»¥ä¸‹æ–‡æ¡£å†…å®¹ä¸­æå–**å…³é”®è¯**ï¼Œè¿™å°†ç”¨äºæ–‡æ¡£æ ¼å¼åŒ–å’Œè§„èŒƒåŒ–ã€‚

        ## åˆ†æè¦æ±‚
        è¯·è¯†åˆ«å¹¶æå–ä»¥ä¸‹ä¸‰ç±»å…³é”®è¯ï¼š

        1. **æ ‡é¢˜å…³é”®è¯**ï¼šè¿™äº›è¯é€šå¸¸å‡ºç°åœ¨æ–‡æ¡£çš„æ ‡é¢˜å’Œå°æ ‡é¢˜ä¸­ï¼Œç”¨äºæè¿°å…·ä½“æ´»åŠ¨æˆ–äº‹ä»¶ã€‚å®ƒä»¬ä¸€èˆ¬æ˜¯**åŠ¨è¯+åè¯**çš„ç»„åˆï¼Œæ ‡è¯†äº†æ–‡æ¡£çš„æ ¸å¿ƒå†…å®¹ã€‚è¯·æå–ä¸æ´»åŠ¨æè¿°ç›´æ¥ç›¸å…³çš„å…³é”®è¯ï¼Œé¿å…é•¿å¥æˆ–çŸ­è¯­ï¼š
           - ä¾‹å¦‚ï¼šä¸¾åŠã€å¼€å±•ã€ååŠ©ã€ç»„ç»‡ã€å¬å¼€ã€å®£è®²ä¼šã€å¿—æ„¿æ´»åŠ¨ã€ç«èµ›ç­‰ã€‚

        2. **å›¾ç‰‡è¯´æ˜å…³é”®è¯**ï¼šè¿™äº›è¯é€šå¸¸ç”¨äºæè¿°å›¾ç‰‡çš„å†…å®¹ï¼Œç®€çŸ­ä¸”ä¸å›¾ç‰‡ç›´æ¥ç›¸å…³ã€‚å…³é”®è¯é€šå¸¸ä¸º**åŠ¨è¯æˆ–åè¯**ï¼Œè€Œéé•¿çŸ­è¯­ã€‚è¯·æå–ä¸å›¾ç‰‡åŠ¨ä½œæˆ–åœºæ™¯ç›¸å…³çš„è¯æ±‡ï¼š
           - ä¾‹å¦‚ï¼šä¸»æŒäººã€å‘è¨€ã€å±•ç¤ºã€åˆå½±ã€æˆè¯¾ã€è®²è§£ç­‰ã€‚

        3. **ç³»ç»Ÿå†—ä½™å…³é”®è¯**ï¼šè¿™äº›æ˜¯è‡ªåŠ¨ç”Ÿæˆçš„æ— å®è´¨æ„ä¹‰çš„è¯ï¼Œé€šå¸¸åŒ…æ‹¬å…ƒæ•°æ®æˆ–æ ¼å¼æ ‡è®°ï¼Œåº”å½“è¢«ç§»é™¤ï¼š
           - ä¾‹å¦‚ï¼šå‘å¸ƒäººã€æµè§ˆæ•°ã€æ—¥æœŸã€å®¡ç¨¿ä¿¡æ¯ï¼ˆå¦‚ä¸€å®¡ã€äºŒå®¡ã€ä¸‰å®¡ï¼‰ç­‰ã€‚

        ## æ–‡æ¡£ä¸Šä¸‹æ–‡
        è¿™ä»½æ–‡æ¡£æ˜¯ä¸€ä¸ª{guess_document_type(content)}ã€‚è¯·æ ¹æ®æ–‡æ¡£ç±»å‹è°ƒæ•´ä½ çš„åˆ†æç­–ç•¥ã€‚

        ## æ–‡æ¡£å†…å®¹å¼€å§‹ï¼š
        {content}
        ## æ–‡æ¡£å†…å®¹ç»“æŸ

        ## è¾“å‡ºè¦æ±‚
        1. æ¯ç±»å…³é”®è¯è‡³å°‘æä¾›**5ä¸ª**ï¼Œæœ€å¤š**15ä¸ª**ã€‚
        2. å…³é”®è¯åº”å½“æ˜¯**å…·ä½“**ä¸”**ç®€çŸ­**ï¼Œé¿å…é•¿å¥æˆ–æè¿°ã€‚
        3. å…³é”®è¯åº”å½“æ˜¯æ–‡æ¡£ä¸­**å®é™…å‡ºç°è¿‡çš„**æˆ–**é«˜åº¦ç›¸å…³**çš„è¯æ±‡ã€‚
        4. ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®ï¼š

        ```json
        {{
          "title_keywords": ["å…³é”®è¯1", "å…³é”®è¯2", ...],
          "image_keywords": ["å…³é”®è¯1", "å…³é”®è¯2", ...],
          "redundant_keywords": ["å…³é”®è¯1", "å…³é”®è¯2", ...]
        }}
        ```

        åªè¿”å›JSONæ•°æ®ï¼Œä¸è¦æœ‰å…¶ä»–ä»»ä½•è§£é‡Šæˆ–è¯´æ˜ã€‚
        """

        
        # æ ¹æ®APIç‰ˆæœ¬è°ƒç”¨ä¸åŒçš„æ–¹æ³•
        if is_old_api:
            # æ—§ç‰ˆAPI (openai < 1.0.0)
            # ä½¿ç”¨æ—§ç‰ˆAPIæ—¶å¿½ç•¥linterè­¦å‘Š
            # noinspection PyUnresolvedReferences
            response = openai.ChatCompletion.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿æå–æ–‡æ¡£ä¸­çš„å…³é”®ä¿¡æ¯ã€‚ä½ çš„å›ç­”åº”å½“ç®€æ´ã€å‡†ç¡®ã€å®ç”¨ï¼Œä¸”å§‹ç»ˆè¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼æ•°æ®ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,  # é™ä½éšæœºæ€§ï¼Œæé«˜ç²¾ç¡®åº¦
                max_tokens=1500
            )
            result = response.choices[0].message.content
        else:
            # æ–°ç‰ˆAPI (openai >= 1.0.0)
            client = openai.OpenAI(**client_params)
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿æå–æ–‡æ¡£ä¸­çš„å…³é”®ä¿¡æ¯ã€‚ä½ çš„å›ç­”åº”å½“ç®€æ´ã€å‡†ç¡®ã€å®ç”¨ï¼Œä¸”å§‹ç»ˆè¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼æ•°æ®ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,  # é™ä½éšæœºæ€§ï¼Œæé«˜ç²¾ç¡®åº¦
                max_tokens=1500
            )
            result = response.choices[0].message.content
        
        try:
            # ç›´æ¥å°è¯•è§£ææ•´ä¸ªå“åº”ä¸ºJSON
            try:
                keywords = json.loads(result)
                return keywords
            except:
                # å¦‚æœæ•´ä¸ªå“åº”ä¸æ˜¯JSONï¼Œå°è¯•æå–JSONéƒ¨åˆ†
                json_start = result.find('{')
                json_end = result.rfind('}') + 1
                if json_start >= 0 and json_end > json_start:
                    json_str = result[json_start:json_end]
                    keywords = json.loads(json_str)
                    return keywords
                else:
                    st.warning("AIè¿”å›çš„ç»“æœä¸åŒ…å«æœ‰æ•ˆçš„JSONæ•°æ®")
                    return None
        except Exception as e:
            st.warning(f"è§£æAIè¿”å›çš„JSONæ•°æ®å¤±è´¥: {str(e)}")
            return None
    except Exception as e:
        st.error(f"è°ƒç”¨OpenAI APIå¤±è´¥: {str(e)}")
        return None

def guess_document_type(content):
    """
    æ ¹æ®å†…å®¹æ¨æµ‹æ–‡æ¡£ç±»å‹
    """
    content_lower = content.lower()
    
    if "åŸ¹è®­" in content_lower or "è®²åº§" in content_lower or "æŠ¥å‘Šä¼š" in content_lower:
        return "åŸ¹è®­æˆ–è®²åº§æ´»åŠ¨æŠ¥å‘Š"
    elif "ç«èµ›" in content_lower or "æ¯”èµ›" in content_lower:
        return "ç«èµ›æ´»åŠ¨æŠ¥å‘Š"
    elif "å¿—æ„¿" in content_lower or "å…¬ç›Š" in content_lower:
        return "å¿—æ„¿æœåŠ¡æ´»åŠ¨æŠ¥å‘Š"
    elif "ä¼šè®®" in content_lower:
        return "ä¼šè®®çºªè¦"
    elif "é€šçŸ¥" in content_lower or "å…¬å‘Š" in content_lower:
        return "é€šçŸ¥å…¬å‘Š"
    else:
        return "å­¦æœ¯æ´»åŠ¨æˆ–æœºæ„æŠ¥å‘Š"

def main():
    st.set_page_config(
        page_title="Wordæ–‡æ¡£æ ¼å¼è§„èŒƒå·¥å…·",
        page_icon="ğŸ“„",
        layout="wide"
    )
    
    # åº”ç”¨æ ‡é¢˜
    st.title("Wordæ–‡æ¡£æ ¼å¼è§„èŒƒå·¥å…·")
    st.markdown("---")
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    init_session_state()

    # åˆå§‹åŒ–èŠå¤©ä¼šè¯çŠ¶æ€
    if 'chat_messages' not in st.session_state:
        st.session_state.chat_messages = []
    if 'chat_token_buffer' not in st.session_state:
        st.session_state.chat_token_buffer = ""
    
    # ä¾§è¾¹æ  - é€‰é¡¹è®¾ç½®
    with st.sidebar:
        # åˆ›å»ºé€‰é¡¹å¡
        sidebar_tab1, sidebar_tab2, sidebar_tab3, sidebar_tab4 = st.tabs(["åŸºæœ¬è®¾ç½®", "AIæ™ºèƒ½", "ç³»ç»Ÿè®¾ç½®", "AIåŠ©æ‰‹"])
        
        # åŸºæœ¬è®¾ç½®é€‰é¡¹å¡
        with sidebar_tab1:
            st.header("æ ¼å¼é€‰é¡¹")
            
            font_name = st.selectbox(
                "å­—ä½“",
                options=["å®‹ä½“", "é»‘ä½“", "å¾®è½¯é›…é»‘", "ä»¿å®‹", "æ¥·ä½“"],
                index=0 if st.session_state.font_name not in ["å®‹ä½“", "é»‘ä½“", "å¾®è½¯é›…é»‘", "ä»¿å®‹", "æ¥·ä½“"] else ["å®‹ä½“", "é»‘ä½“", "å¾®è½¯é›…é»‘", "ä»¿å®‹", "æ¥·ä½“"].index(st.session_state.font_name)
            )
            st.session_state.font_name = font_name
            
            font_size = st.select_slider(
                "å­—ä½“å¤§å°",
                options=[10, 12, 14, 16, 18],
                value=st.session_state.font_size
            )
            st.session_state.font_size = font_size
            
            indent = st.checkbox("é¦–è¡Œç¼©è¿›", value=st.session_state.indent)
            st.session_state.indent = indent
            
            st.header("å…³é”®è¯è®¾ç½®")
            
            title_keywords_text = st.text_area(
                "æ ‡é¢˜å…³é”®è¯",
                value=", ".join(st.session_state.title_keywords),
                height=100
            )
            title_keywords = [kw.strip() for kw in title_keywords_text.split(",") if kw.strip()]
            st.session_state.title_keywords = title_keywords
            
            image_keywords_text = st.text_area(
                "å›¾ç‰‡è¯´æ˜å…³é”®è¯",
                value=", ".join(st.session_state.image_keywords),
                height=100
            )
            image_keywords = [kw.strip() for kw in image_keywords_text.split(",") if kw.strip()]
            st.session_state.image_keywords = image_keywords
            
            redundant_keywords_text = st.text_area(
                "ç³»ç»Ÿå†—ä½™å…³é”®è¯",
                value=", ".join(st.session_state.redundant_keywords),
                height=100
            )
            redundant_keywords = [kw.strip() for kw in redundant_keywords_text.split(",") if kw.strip()]
            st.session_state.redundant_keywords = redundant_keywords
            
            if st.button("ä¿å­˜åŸºæœ¬è®¾ç½®"):
                if update_config():
                    st.success("è®¾ç½®å·²ä¿å­˜åˆ°é…ç½®æ–‡ä»¶")
                else:
                    st.error("ä¿å­˜è®¾ç½®å¤±è´¥")
        
        # AIæ™ºèƒ½é€‰é¡¹å¡
        with sidebar_tab2:
            st.header("AIæ™ºèƒ½è®¾ç½®")
            
            enable_ai = st.toggle("å¯ç”¨AIæ™ºèƒ½å…³é”®è¯åˆ†æ", value=st.session_state.enable_ai)
            st.session_state.enable_ai = enable_ai
            
            if enable_ai:
                with st.form(key="api_settings"):
                    st.subheader("OpenAI API è®¾ç½®")
                    
                    api_key = st.text_input(
                        "OpenAI API å¯†é’¥",
                        type="password",
                        value=st.session_state.api_key,
                        help="è¾“å…¥ä½ çš„OpenAI APIå¯†é’¥"
                    )
                    
                    model = st.text_input(
                        "æ¨¡å‹åç§°",
                        value=st.session_state.model,
                        help="è¾“å…¥ç”¨äºåˆ†æçš„AIæ¨¡å‹åç§°ï¼Œä¾‹å¦‚ï¼šgpt-3.5-turboã€gpt-4ç­‰"
                    )
                    
                    api_base = st.text_input(
                        "API Base URL (å¯é€‰)",
                        value=st.session_state.api_base,
                        help="é€‚ç”¨äºä½¿ç”¨ä»£ç†æˆ–è‡ªå®šä¹‰APIç«¯ç‚¹ï¼Œç•™ç©ºä½¿ç”¨OpenAIé»˜è®¤åœ°å€"
                    )
                    
                    submit_button = st.form_submit_button(label="ä¿å­˜AIè®¾ç½®")
                    
                    if submit_button:
                        st.session_state.api_key = api_key
                        st.session_state.model = model
                        st.session_state.api_base = api_base
                        if update_config():
                            st.success("AIè®¾ç½®å·²ä¿å­˜åˆ°é…ç½®æ–‡ä»¶!")
                        else:
                            st.error("ä¿å­˜AIè®¾ç½®å¤±è´¥")
                
                if st.button("æµ‹è¯•APIè¿æ¥"):
                    if not st.session_state.api_key:
                        st.error("è¯·å…ˆè®¾ç½®APIå¯†é’¥!")
                    else:
                        with st.spinner("æ­£åœ¨æµ‹è¯•APIè¿æ¥..."):
                            try:
                                openai.api_key = st.session_state.api_key
                                
                                # å‡†å¤‡å®¢æˆ·ç«¯å‚æ•°
                                client_params = {"api_key": st.session_state.api_key}
                                if st.session_state.api_base.strip():
                                    if is_old_api:
                                        openai.api_base = st.session_state.api_base
                                    else:
                                        client_params["base_url"] = st.session_state.api_base
                                
                                if is_old_api:
                                    # æ—§ç‰ˆAPI - å¿½ç•¥linterè­¦å‘Š
                                    # noinspection PyUnresolvedReferences
                                    response = openai.ChatCompletion.create(
                                        model=st.session_state.model,
                                        messages=[{"role": "user", "content": "Hello, World!"}],
                                        max_tokens=5
                                    )
                                else:
                                    # æ–°ç‰ˆAPI
                                    client = openai.OpenAI(**client_params)
                                    response = client.chat.completions.create(
                                        model=st.session_state.model,
                                        messages=[{"role": "user", "content": "Hello, World!"}],
                                        max_tokens=5
                                    )
                                
                                st.success("APIè¿æ¥æµ‹è¯•æˆåŠŸ!")
                            except Exception as e:
                                st.error(f"APIè¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
        
        # ç³»ç»Ÿè®¾ç½®é€‰é¡¹å¡
        with sidebar_tab3:
            st.header("ç³»ç»Ÿè®¾ç½®")
            
            config_dir = st.text_input(
                "é…ç½®æ–‡ä»¶ç›®å½•",
                value=st.session_state.get('config_dir', get_config_dir()),
                help="è®¾ç½®é…ç½®æ–‡ä»¶å­˜å‚¨ç›®å½•ï¼Œç•™ç©ºä½¿ç”¨é»˜è®¤ç›®å½•"
            )
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("é€‰æ‹©ç›®å½•"):
                    try:
                        import tkinter as tk
                        from tkinter import filedialog
                        
                        root = tk.Tk()
                        root.withdraw()
                        
                        folder_path = filedialog.askdirectory(
                            title="é€‰æ‹©é…ç½®æ–‡ä»¶ç›®å½•",
                            initialdir=config_dir if os.path.exists(config_dir) else os.path.expanduser("~")
                        )
                        
                        if folder_path:
                            st.session_state.config_dir = folder_path
                            config_dir = folder_path
                            st.rerun()
                    except Exception as e:
                        st.error(f"é€‰æ‹©ç›®å½•å¤±è´¥: {str(e)}")
            
            with col2:
                if st.button("æ‰“å¼€é…ç½®ç›®å½•"):
                    try:
                        os.startfile(get_config_dir())
                    except Exception as e:
                        st.error(f"æ— æ³•æ‰“å¼€ç›®å½•: {str(e)}")
            
            if st.button("åº”ç”¨é…ç½®ç›®å½•"):
                if config_dir and config_dir != get_config_dir():
                    try:
                        # ä¿å­˜å½“å‰é…ç½®è·¯å¾„
                        old_config_dir = get_config_dir()
                        
                        # æ›´æ–°ä¼šè¯çŠ¶æ€
                        st.session_state.config_dir = config_dir
                        
                        # ç¡®ä¿æ–°ç›®å½•å­˜åœ¨
                        if not os.path.exists(config_dir):
                            os.makedirs(config_dir)
                        
                        # å¦‚æœæ—§é…ç½®å­˜åœ¨ï¼Œå¤åˆ¶åˆ°æ–°ç›®å½•
                        old_config_path = os.path.join(old_config_dir, 'config.json')
                        new_config_path = os.path.join(config_dir, 'config.json')
                        
                        if os.path.exists(old_config_path) and not os.path.exists(new_config_path):
                            shutil.copy2(old_config_path, new_config_path)
                        
                        st.success(f"é…ç½®ç›®å½•å·²æ›´æ”¹ä¸º: {config_dir}")
                        # é‡æ–°åŠ è½½é…ç½®
                        init_session_state()
                    except Exception as e:
                        st.error(f"åº”ç”¨é…ç½®ç›®å½•å¤±è´¥: {str(e)}")
            
            st.markdown("---")
            
            if st.button("æ¢å¤é»˜è®¤è®¾ç½®"):
                if st.session_state.get('confirm_reset', False):
                    # é‡ç½®ä¸ºé»˜è®¤é…ç½®
                    for key, value in DEFAULT_CONFIG.items():
                        if isinstance(value, dict):
                            for sub_key, sub_value in value.items():
                                if f"{key}_{sub_key}" in st.session_state:
                                    st.session_state[f"{key}_{sub_key}"] = sub_value
                                elif sub_key in st.session_state:
                                    st.session_state[sub_key] = sub_value
                        else:
                            if key in st.session_state:
                                st.session_state[key] = value
                    
                    # æ¢å¤é»˜è®¤é…ç½®æ–‡ä»¶
                    save_config(DEFAULT_CONFIG)
                    
                    st.session_state.confirm_reset = False
                    st.success("å·²æ¢å¤é»˜è®¤è®¾ç½®")
                    st.rerun()
                else:
                    st.session_state.confirm_reset = True
                    st.warning("âš ï¸ ç¡®å®šè¦æ¢å¤é»˜è®¤è®¾ç½®å—ï¼Ÿå†æ¬¡ç‚¹å‡»\"æ¢å¤é»˜è®¤è®¾ç½®\"ç¡®è®¤ã€‚")
            else:
                # é‡ç½®ç¡®è®¤çŠ¶æ€
                if 'confirm_reset' in st.session_state:
                    st.session_state.confirm_reset = False
                    
        # AIåŠ©æ‰‹é€‰é¡¹å¡ - ä¸AIèŠå¤©çš„åŠŸèƒ½
        with sidebar_tab4:
            st.header("AIåŠ©æ‰‹")
            
            if not st.session_state.api_key:
                st.warning("è¯·å…ˆåœ¨ã€ŒAIæ™ºèƒ½ã€è®¾ç½®ä¸­é…ç½®APIå¯†é’¥")
            else:
                # æ˜¾ç¤ºèŠå¤©å†å²
                chat_container = st.container()
                with chat_container:
                    for msg in st.session_state.chat_messages:
                        with st.chat_message(msg["role"]):
                            st.markdown(msg["content"])
                
                # ç”¨æˆ·è¾“å…¥
                user_input = st.chat_input("è¾“å…¥ä½ çš„é—®é¢˜ï¼š")
                
                if user_input:
                    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°èŠå¤©å†å²
                    st.session_state.chat_messages.append({"role": "user", "content": user_input})
                    
                    # åœ¨ç•Œé¢ä¸Šæ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
                    with st.chat_message("user"):
                        st.markdown(user_input)
                    
                    # åœ¨ç•Œé¢ä¸Šæ·»åŠ åŠ©æ‰‹æ¶ˆæ¯å ä½ç¬¦
                    with st.chat_message("assistant"):
                        message_placeholder = st.empty()
                    
                    try:
                        # åˆ›å»ºæ¶ˆæ¯åˆ—è¡¨
                        messages = [{"role": msg["role"], "content": msg["content"]} for msg in st.session_state.chat_messages]
                        
                        # è®¾ç½®API
                        openai.api_key = st.session_state.api_key
                        client_params = {"api_key": st.session_state.api_key}
                        
                        if st.session_state.api_base.strip():
                            if is_old_api:
                                openai.api_base = st.session_state.api_base
                            else:
                                client_params["base_url"] = st.session_state.api_base
                        
                        full_response = ""
                        
                        # æµå¼å“åº”
                        if is_old_api:
                            # æ—§ç‰ˆAPI - å¿½ç•¥linterè­¦å‘Š
                            # noinspection PyUnresolvedReferences
                            response = openai.ChatCompletion.create(
                                model=st.session_state.model,
                                messages=messages,
                                stream=True
                            )
                            
                            for chunk in response:
                                if chunk.choices[0].get("delta", {}).get("content"):
                                    content = chunk.choices[0]["delta"]["content"]
                                    full_response += content
                                    message_placeholder.markdown(full_response + "â–Œ")
                        else:
                            # æ–°ç‰ˆAPI
                            client = openai.OpenAI(**client_params)
                            stream = client.chat.completions.create(
                                model=st.session_state.model,
                                messages=messages,
                                stream=True
                            )
                            
                            for chunk in stream:
                                if chunk.choices[0].delta.content:
                                    content = chunk.choices[0].delta.content
                                    full_response += content
                                    message_placeholder.markdown(full_response + "â–Œ")
                        
                        # æ›´æ–°æœ€ç»ˆå“åº”
                        message_placeholder.markdown(full_response)
                        
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«JSONæ•°æ®å¹¶æå–
                        try:
                            json_start = full_response.find('{')
                            json_end = full_response.rfind('}') + 1
                            
                            if json_start >= 0 and json_end > json_start:
                                json_str = full_response[json_start:json_end]
                                try:
                                    keywords_data = json.loads(json_str)
                                    
                                    # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®è¯å­—æ®µ
                                    if any(k in keywords_data for k in ["title_keywords", "image_keywords", "redundant_keywords"]):
                                        st.success("æ£€æµ‹åˆ°å…³é”®è¯æ•°æ®ï¼")
                                        
                                        # åˆ›å»ºåº”ç”¨æŒ‰é’®
                                        if st.button("åº”ç”¨è¿™äº›å…³é”®è¯"):
                                            # æ›´æ–°å…³é”®è¯
                                            if "title_keywords" in keywords_data and keywords_data["title_keywords"]:
                                                st.session_state.title_keywords = keywords_data["title_keywords"]
                                            
                                            if "image_keywords" in keywords_data and keywords_data["image_keywords"]:
                                                st.session_state.image_keywords = keywords_data["image_keywords"]
                                            
                                            if "redundant_keywords" in keywords_data and keywords_data["redundant_keywords"]:
                                                st.session_state.redundant_keywords = keywords_data["redundant_keywords"]
                                            
                                            # ä¿å­˜é…ç½®
                                            if update_config():
                                                st.success("æˆåŠŸåº”ç”¨å…³é”®è¯ï¼")
                                                st.rerun()
                                            else:
                                                st.error("ä¿å­˜é…ç½®å¤±è´¥")
                                        
                                        # æ˜¾ç¤ºå…³é”®è¯é¢„è§ˆ
                                        with st.expander("é¢„è§ˆå…³é”®è¯"):
                                            if "title_keywords" in keywords_data:
                                                st.write("**æ ‡é¢˜å…³é”®è¯:**")
                                                st.write(", ".join(keywords_data["title_keywords"]))
                                            
                                            if "image_keywords" in keywords_data:
                                                st.write("**å›¾ç‰‡è¯´æ˜å…³é”®è¯:**")
                                                st.write(", ".join(keywords_data["image_keywords"]))
                                            
                                            if "redundant_keywords" in keywords_data:
                                                st.write("**ç³»ç»Ÿå†—ä½™å…³é”®è¯:**")
                                                st.write(", ".join(keywords_data["redundant_keywords"]))
                                except Exception as e:
                                    st.warning(f"è§£æJSONå¤±è´¥: {str(e)}")
                        except Exception as e:
                            pass  # å¦‚æœæ²¡æœ‰JSONæ•°æ®ï¼Œå¿½ç•¥é”™è¯¯
                            
                        # æ·»åŠ åŠ©æ‰‹å“åº”åˆ°èŠå¤©å†å²
                        st.session_state.chat_messages.append({"role": "assistant", "content": full_response})
                        
                    except Exception as e:
                        st.error(f"å‘ç”Ÿé”™è¯¯: {str(e)}")
                
                # æ¸…ç©ºèŠå¤©æŒ‰é’®
                if st.button("æ¸…ç©ºèŠå¤©è®°å½•"):
                    st.session_state.chat_messages = []
                    st.rerun()

    # ä¸»ç•Œé¢ - æ ‡ç­¾é¡µ
    tab1, tab2 = st.tabs(["å•æ–‡ä»¶å¤„ç†", "æ‰¹é‡å¤„ç†"])
    
    # åˆ›å»ºé¢„è§ˆåŒºåŸŸå®¹å™¨ï¼Œåœ¨ä»»ä½•é€‰é¡¹å¡ä¹‹å¤–ï¼Œä½œä¸ºå…±äº«é¢„è§ˆåŒºåŸŸ
    preview_container = st.container()
    
    # å•æ–‡ä»¶å¤„ç†æ ‡ç­¾é¡µ
    with tab1:
        st.header("å•æ–‡ä»¶å¤„ç†")
        
        uploaded_file = st.file_uploader("é€‰æ‹©Wordæ–‡æ¡£", type=["docx"], key="single_file")
        
        if uploaded_file is not None:
            st.write(f"å·²é€‰æ‹©: {uploaded_file.name}")
            
            # é¢„å¤„ç† - æå–åŸå§‹æ–‡æ¡£å†…å®¹
            with st.spinner("åŠ è½½é¢„è§ˆ..."):
                input_paragraphs = extract_docx_text(uploaded_file)
            
            # AIåˆ†ææŒ‰é’® - ä»…åœ¨å¯ç”¨AIå’Œä¸Šä¼ æ–‡ä»¶åæ˜¾ç¤º
            if st.session_state.enable_ai and 'api_key' in st.session_state and st.session_state.api_key:
                if st.button("ä½¿ç”¨AIåˆ†æå…³é”®è¯", key="analyze_ai_single"):
                    with st.spinner("AIæ­£åœ¨åˆ†ææ–‡æ¡£..."):
                        content = extract_content_for_ai(uploaded_file)
                        keywords = analyze_with_openai(
                            content, 
                            st.session_state.api_key,
                            st.session_state.model,
                            st.session_state.api_base
                        )
                        
                        if keywords:
                            # æ›´æ–°ä¼šè¯çŠ¶æ€ä¸­çš„å…³é”®è¯
                            if 'title_keywords' in keywords and keywords['title_keywords']:
                                st.session_state.title_keywords = keywords['title_keywords']
                                title_keywords = keywords['title_keywords']
                            
                            if 'image_keywords' in keywords and keywords['image_keywords']:
                                st.session_state.image_keywords = keywords['image_keywords']
                                image_keywords = keywords['image_keywords']
                            
                            if 'redundant_keywords' in keywords and keywords['redundant_keywords']:
                                st.session_state.redundant_keywords = keywords['redundant_keywords']
                                redundant_keywords = keywords['redundant_keywords']
                            
                            st.success("AIåˆ†æå®Œæˆï¼Œå…³é”®è¯å·²æ›´æ–°!")
                            # æ˜¾ç¤ºåˆ†æç»“æœ
                            with st.expander("æŸ¥çœ‹AIåˆ†æç»“æœ"):
                                st.write("**æ ‡é¢˜å…³é”®è¯:**")
                                st.write(", ".join(st.session_state.title_keywords))
                                st.write("**å›¾ç‰‡è¯´æ˜å…³é”®è¯:**")
                                st.write(", ".join(st.session_state.image_keywords))
                                st.write("**ç³»ç»Ÿå†—ä½™å…³é”®è¯:**")
                                st.write(", ".join(st.session_state.redundant_keywords))
            
            # åˆ›å»ºå¤„ç†æŒ‰é’®å’Œç»“æœå®¹å™¨
            process_btn = st.button("å¼€å§‹å¤„ç†", key="process_single")
            result_container = st.container()

            output_paragraphs = None  # åˆå§‹åŒ–è¾“å‡ºæ®µè½å˜é‡
            
            # åœ¨å¤„ç†æŒ‰é’®ç‚¹å‡»åå¤„ç†æ–‡æ¡£
            if process_btn:
                with st.spinner("å¤„ç†ä¸­..."):
                    output_file, output_paragraphs = process_single_file(
                        uploaded_file,
                        title_keywords,
                        image_keywords,
                        st.session_state.font_name,
                        st.session_state.font_size,
                        st.session_state.indent
                    )
                    
                    if output_file and output_paragraphs:
                        with result_container:
                            st.success("å¤„ç†å®Œæˆ!")
                            st.markdown(
                                get_binary_file_downloader_html(output_file, 'ç‚¹å‡»ä¸‹è½½å¤„ç†åçš„æ–‡ä»¶'),
                                unsafe_allow_html=True
                            )
            
            # æ›´æ–°é¢„è§ˆåŒºåŸŸï¼ˆè¿™éƒ¨åˆ†ä¼šåœ¨ä¸Šä¼ æ–‡ä»¶åç«‹å³æ‰§è¡Œï¼Œå¹¶åœ¨å¤„ç†å®Œæˆåå†æ¬¡æ›´æ–°ï¼‰
            with preview_container:
                update_preview_area(input_paragraphs, output_paragraphs)
    
    # æ‰¹é‡å¤„ç†æ ‡ç­¾é¡µ
    with tab2:
        st.header("æ‰¹é‡å¤„ç†")
        
        uploaded_files = st.file_uploader("é€‰æ‹©å¤šä¸ªWordæ–‡æ¡£", type=["docx"], accept_multiple_files=True, key="batch_files")
        
        batch_input_paragraphs = None
        batch_output_paragraphs = None
        
        if uploaded_files:
            st.write(f"å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶")
            
            file_list = ""
            for file in uploaded_files:
                file_list += f"- {file.name}\n"
            
            st.markdown(file_list)
            
            # é¢„è§ˆé€‰æ‹©çš„æ–‡ä»¶
            if len(uploaded_files) > 0:
                preview_file = st.selectbox(
                    "é€‰æ‹©è¦é¢„è§ˆçš„æ–‡ä»¶",
                    options=[file.name for file in uploaded_files],
                    index=0
                )
                
                # è·å–é€‰ä¸­çš„æ–‡ä»¶å¯¹è±¡
                selected_file = next((f for f in uploaded_files if f.name == preview_file), None)
                
                if selected_file:
                    with st.spinner("åŠ è½½é¢„è§ˆ..."):
                        batch_input_paragraphs = extract_docx_text(selected_file)
            
            output_files = None  # åˆå§‹åŒ–è¾“å‡ºæ–‡ä»¶åˆ—è¡¨
            
            if st.button("å¼€å§‹æ‰¹é‡å¤„ç†", key="process_batch"):
                with st.spinner("æ‰¹é‡å¤„ç†ä¸­..."):
                    output_files = process_batch_files(
                        uploaded_files,
                        st.session_state.title_keywords,
                        st.session_state.image_keywords,
                        st.session_state.font_name,
                        st.session_state.font_size,
                        st.session_state.indent
                    )
                    
                    if output_files:
                        st.success(f"æ‰¹å¤„ç†å®Œæˆ! å…±å¤„ç† {len(output_files)} ä¸ªæ–‡ä»¶")
                        
                        # åˆ›å»ºZIPæ–‡ä»¶å¹¶æä¾›ä¸‹è½½
                        zip_file = create_zip_of_files(output_files)
                        st.markdown(
                            get_binary_file_downloader_html(zip_file, 'ç‚¹å‡»ä¸‹è½½æ‰€æœ‰å¤„ç†åçš„æ–‡ä»¶ (ZIP)'),
                            unsafe_allow_html=True
                        )
                        
                        # æ›´æ–°é¢„è§ˆä»¥æ˜¾ç¤ºå¤„ç†åçš„å†…å®¹
                        if len(output_files) > 0:
                            preview_output_file = st.selectbox(
                                "é€‰æ‹©è¦é¢„è§ˆçš„å¤„ç†åæ–‡ä»¶",
                                options=[filename for filename, _ in output_files],
                                index=0
                            )
                            
                            # è·å–é€‰ä¸­çš„æ–‡ä»¶è·¯å¾„
                            selected_output_path = next((filepath for filename, filepath in output_files if filename == preview_output_file), None)
                            
                            if selected_output_path:
                                batch_output_paragraphs = extract_docx_text(selected_output_path)
                        
                        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                        for _, filepath in output_files:
                            if os.path.exists(filepath):
                                os.unlink(filepath)
                        if os.path.exists(zip_file):
                            os.unlink(zip_file)
            
            # æ›´æ–°æ‰¹å¤„ç†é¢„è§ˆ
            if batch_input_paragraphs:
                with preview_container:
                    update_preview_area(batch_input_paragraphs, batch_output_paragraphs)
    
    # é¡µè„š
    st.markdown("---")
    st.caption("Wordæ–‡æ¡£æ ¼å¼è§„èŒƒå·¥å…· Â© 2023")

def update_preview_area(input_paragraphs, output_paragraphs=None):
    """æ›´æ–°ç»Ÿä¸€çš„é¢„è§ˆåŒºåŸŸ"""
    st.header("æ–‡ä»¶é¢„è§ˆ")
    
    if not input_paragraphs:
        st.info("è¯·ä¸Šä¼ æ–‡ä»¶ä»¥æŸ¥çœ‹é¢„è§ˆ")
        return
    
    # å¦‚æœæ²¡æœ‰å¤„ç†åçš„å†…å®¹ï¼Œåªæ˜¾ç¤ºè¾“å…¥æ–‡ä»¶
    if output_paragraphs is None:
        st.subheader("åŸå§‹æ–‡æ¡£")
        render_preview(input_paragraphs)
    else:
        # æœ‰å¤„ç†åçš„å†…å®¹ï¼Œæ˜¾ç¤ºå¯¹æ¯”è§†å›¾
        st.subheader("æ–‡æ¡£å¯¹æ¯”")
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### åŸå§‹æ–‡æ¡£")
            render_preview(input_paragraphs, max_height=600)
        
        with col2:
            st.markdown("#### å¤„ç†åæ–‡æ¡£")
            render_preview(output_paragraphs, max_height=600)

if __name__ == "__main__":
    main()
